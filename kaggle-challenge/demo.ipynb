{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from core.train_utils import train_bert, test_bert\n",
    "from core.dataset_utils import TextDatasetBert, TextDatasetLSTM\n",
    "from core.model_utils import get_cate_keywords, embedding_from_pretrain, get_embeddings\n",
    "from core.LSTM_model import ReviewClassifier\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "source": [
    "#### Load preprocessed review data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = pickle.load(open(os.path.join('Data/processed', 'processed_data.pkl'), 'rb'))\n",
    "var_names = ['train_docs', 'val_docs', 'test_docs', 'train_labels', 'val_labels', 'ind2label', 'label2ind']\n",
    "for var in var_names:\n",
    "    exec(\"{} = save_file['{}']\".format(var, var))\n",
    "\n",
    "save_file = pickle.load(open(os.path.join('Data/processed', 'processed_bert_emb.pkl'), 'rb'))\n",
    "var_names = ['X_train_emb', 'X_val_emb', 'X_test_emb']\n",
    "for var in var_names:\n",
    "    exec(\"{} = save_file['{}']\".format(var, var))"
   ]
  },
  {
   "source": [
    "#### Train Bert-based model with center loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDatasetBert(X_train_emb, train_labels)\n",
    "val_dataset = TextDatasetBert(X_val_emb, val_labels)\n",
    "test_dataset = TextDatasetBert(X_test_emb, np.zeros(len(X_test_emb['input_ids'])))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = train_bert(train_loader, val_loader, device, num_epoch=1, LR_Bert=1e-6, alpha_CL=0.1, LR_CL=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = os.path.join('models', 'best_bert_finetuned_model')\n",
    "test_bert(best_model_name, test_loader, ind2label, device)"
   ]
  },
  {
   "source": [
    "#### Train LSTM-based model with attention layer and center loss on keywords"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_keywords = get_cate_keywords(train_docs, train_labels)\n",
    "\n",
    "ind = 1\n",
    "print (ind2label[ind])\n",
    "wordcloud = WordCloud(width=800, height=500,background_color=\"white\").generate(' '.join(cate_keywords[ind]))\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cnts = Counter()\n",
    "for corpus in [train_docs, val_docs, test_docs]:\n",
    "    for line in corpus:\n",
    "        word_cnts.update(line)\n",
    "\n",
    "ind2word = ['UNK', 'PAD']\n",
    "for word, cnts in word_cnts.items():\n",
    "    if cnts <= 3:\n",
    "        continue\n",
    "    ind2word.append(word)\n",
    "emb_matrix, word2ind = get_embeddings(ind2word, os.path.join('embeddings', 'glove.42B.300d.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDatasetLSTM(train_docs, train_labels, word2ind=word2ind)\n",
    "val_dataset = TextDatasetLSTM(val_docs, val_labels, word2ind=word2ind)\n",
    "test_dataset = TextDatasetLSTM(test_docs, np.zeros(len(test_docs)), word2ind=word2ind)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "lstm_model = ReviewClassifier(emb_matrix, cate_keywords, word2ind, ind2label, use_attention=True, hidden_dim=100, num_labels=10, device=device, lstm_model_name=None, center_name=None)\n",
    "lstm_model.train(train_loader, val_loader, lstm_lr=1e-4, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_name = os.path.join('models', 'kw_best_lstm')\n",
    "center_model_name = os.path.join('models', 'kw_best_center')\n",
    "\n",
    "best_lstm_model = ReviewClassifier(emb_matrix, cate_keywords, word2ind, ind2label, hidden_dim=100, num_labels=10, device=device, lstm_model_name=lstm_model_name, center_name=center_model_name)\n",
    "\n",
    "best_lstm_model.validation(val_loader)\n",
    "best_lstm_model.test(test_loader)"
   ]
  }
 ]
}